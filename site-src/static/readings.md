---
title: Reading List
---
## Reading List
This is a list of papers that I've found personally really useful to learn from first principles some key deep learning concepts. I recommend reading through them a few times and take notes on what the authors emphasize as important.

### [Original LSTM Paper](https://www.researchgate.net/publication/13853244_Long_Short-term_Memory)

### [Overview of Computational Complexity for Gradient-Based Learning Algorithms](https://web.stanford.edu/class/psych209a/ReadingsByDate/02_25/Williams%20Zipser95RecNets.pdf)

### [LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages](ftp://ftp.idsia.ch/pub/juergen/L-IEEE.pdf)

### [Original GRU Paper](https://arxiv.org/pdf/1406.1078.pdf)

### [Original Attention Paper](https://arxiv.org/pdf/1409.0473.pdf)

### [Hierarchical Attention Networks for Document Classification](http://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf)
