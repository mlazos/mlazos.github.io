<!DOCTYPE html>
<html lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

        <title>Mike Lazos - Cross-Domain Distribution Matching with Triangle GANs</title>

        <link rel="stylesheet" type="text/css" href="//netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css" />
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">

        <link rel="stylesheet" type="text/css" href="../css/syntax.css" />
        <link rel="stylesheet" type="text/css" href="../css/custom.css" />
    </head>
    <body>
        <nav class="navbar navbar-default navbar-static-top">
            <div class="container-fluid">
                <div class="navbar-header">
                    <a class="navbar-brand" href="#">Mike Lazos</a>
                </div>
                <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                    <ul class="nav navbar-nav">
                        <li><a href="../index.html">Home</a></li>
                        <li><a href="../about.html">About</a></li>
                        <li><a href="../projects.html">Projects</a></li>
                        <li><a href="../posts.html">Posts</a></li>
                        <li><a href="../readings.html">Reading List</a></li>
                    </ul>
                    <ul class="nav navbar-nav navbar-right">
                        <li><a href="http://github.com/mlazos"><i class="fa fa-github fa-lg fa-fw"></i></a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <div class="container">
            <div class="row">
                <div class="col-md-10 col-md-offset-1">
                    <div class="page-header">
    <h1>Cross-Domain Distribution Matching with Triangle GANs</h1>
    <small>Posted on December 28, 2017 <a href="../posts/2017-12-28-Joint-Distribution-Matching-Triangle-Gan.html"><i class="fa fa-link fa-lg fa-fw"></i></a></small>
</div>

<p>This is a tutorial on implementing <a href="https://papers.nips.cc/paper/7109-triangle-generative-adversarial-networks">Triangle Generative Adversarial Networks</a> from NIPS 2017. This is useful as a deep learning exercise in tensorflow while also learning about some of the newest research in generative adversarial models. For reference, all of the code in this tutorial is <a href="https://github.com/mlazos/triangle-gan-tf">available on Github</a>.</p>
<h3 id="motivation-and-background">Motivation and Background</h3>
<p>Cross-Domain joint distribution matching is the problem of taking samples from two domains, like text and images, and learning a joint distribution over them <em>i.e.</em> generate a random image along with its caption. The intuition here is that we would like to learn a mapping that matches samples from one domain to samples of the other. An example of this is attribute-conditional image generation, where given some attributes of an image, we want to generate a random image with those attributes. This is easily achievable if fully paired data is available, but often a fully labeled dataset is difficult to gather. There are multiple proposed solutions to this, including many fully unsupervised methods. These however have an important drawback, mainly that without any label information the learned mapping between the domains may not be the desired one - for instance, the model may learn that the attribute ‘man’ maps to a child image as long as the discriminator agrees and the reconstruction error is small. To solve this problem, triangle-GAN uses a few paired samples to inform the discriminators what kind of mapping is desired.</p>
<h3 id="triangle-gan-architecture">Triangle GAN Architecture</h3>
<div style="text-align:center" markdown="1">
<div class="figure">
<img src="../resources/triangle_gan_architecture_75.jpg" title="Triangle GAN Architecture" alt="Figure 1: Triangle Gan Architecture from Gan et al." style="width:80.0%" />
<p class="caption"><strong>Figure 1</strong>: Triangle Gan Architecture from <a href="https://papers.nips.cc/paper/7109-triangle-generative-adversarial-networks">Gan et al.</a></p>
</div>
</div>
<p>The Triangle GAN consists of two generators, <span class="math inline">\(G_y\)</span>, <span class="math inline">\(G_x\)</span> and two discriminators <span class="math inline">\(D_1\)</span>, <span class="math inline">\(D_2\)</span> with the goal of learning how to generate samples <span class="math inline">\((x,y)\)</span> from the distribution <span class="math inline">\(p(x, y)\)</span>. As a motivating example, let’s understand the architecture for the problem of generating a random image along with a random caption that describes that image. An initial assumption of this model is that we can easily sample from our two domains independently, so in this problem we should be able to sample from the space of images and also from the space of captions. In order to generate our <span class="math inline">\((image, caption)\)</span> pairs we need a way to generate an image given a caption and vice versa. This is where the generators come in. The generator <span class="math inline">\(G_{c}\)</span> generates <span class="math inline">\(caption_{G_c}\)</span> from <span class="math inline">\(p_{G_c}(caption|image)\)</span> which after training should approximate the true <span class="math inline">\(p(caption|image)\)</span> distribution. Similarly the generator <span class="math inline">\(G_{i}\)</span> generates <span class="math inline">\(image_{G_i}\)</span> from <span class="math inline">\(p_{G_i}(image|caption)\)</span>. With these two generators two versions of the joint distribution can be defined. <span class="math inline">\(G_c\)</span> induces the distribution <span class="math inline">\(p_{G_c}(image, caption)=p_{G_c}(caption|image)p(image)\)</span> while <span class="math inline">\(G_i\)</span> induces <span class="math inline">\(p_{G_i}(image, caption)=p_{G_i}(image|caption)p(caption)\)</span>. So in order to create a pair <span class="math inline">\((image, caption)\)</span> we can either first sample an image from <span class="math inline">\(p(image)\)</span> and then using <span class="math inline">\(G_c\)</span> generate an associated caption from <span class="math inline">\(p_{G_c}(caption|image)\)</span> or we can first sample a caption and use <span class="math inline">\(G_c\)</span> to generate an associated image from <span class="math inline">\(p_{G_i}(image|caption)\)</span>. So we have two kinds of pairs that we can generate, <span class="math inline">\((image, caption_{G_c})\)</span> and <span class="math inline">\((image_{G_i}, caption)\)</span>. Now the discriminators work in tandem to distinguish a small number of real pairs from the two kinds of generated pairs. In order to do this, <span class="math inline">\(D_1\)</span> tries to distinguish whether an <span class="math inline">\((image, caption)\)</span> sample is real or fake, so it receives real samples, and samples from our two generators. <span class="math inline">\(D_2\)</span> alternatively tries to distinguish whether a sample pair was generated from <span class="math inline">\(G_i\)</span> or <span class="math inline">\(G_c\)</span>. Intuitively, <span class="math inline">\(D_1\)</span> informs the generators what kind of mapping they should be learning while <span class="math inline">\(D_2\)</span> serves the role of forcing the generators to approximate similar distributions.</p>
<h3 id="implementation">Implementation</h3>
<p>For the implementation, we’ll be replicating a toy problem from the <a href="https://papers.nips.cc/paper/7109-triangle-generative-adversarial-networks">paper</a>. The goal of this problem is to train Triangle-GAN to sample from a mixture of four Gaussian distributions in 2D. We’ll treat the <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> coordinates as our separate domains. <a href="https://github.com/mlazos/triangle-gan-tf">The full code is on Github</a>.</p>
<p>First let’s build some helper functions to create the different components of the model. What we’ll need is a multi-layer feedforward network - this will be the basic building block of the generators and discriminators.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">    <span class="co"># for each layer create a weight matrix and bias vector</span>
    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, num_hidden_layers):
        <span class="cf">with</span> tf.variable_scope(<span class="st">&quot;dense&quot;</span> <span class="op">+</span> <span class="bu">str</span>(i)):
            w_n <span class="op">=</span> tf.get_variable(
                <span class="st">&quot;w_&quot;</span> <span class="op">+</span> <span class="bu">str</span>(i), 
                [prev_input_dim, hidden_dim], initializer<span class="op">=</span>tf.initializers.random_normal(<span class="dv">0</span>, <span class="dv">1</span>))
            b_n <span class="op">=</span> tf.get_variable(
                <span class="st">&quot;b_&quot;</span> <span class="op">+</span> <span class="bu">str</span>(i), 
                [hidden_dim], 
                initializer<span class="op">=</span>tf.initializers.random_normal(<span class="dv">0</span>, <span class="dv">1</span>))
            prev_input_dim <span class="op">=</span> hidden_dim
            prev_output <span class="op">=</span> hidden_activation(
                tf.matmul(prev_output, w_n) <span class="op">+</span> b_n)
    <span class="cf">with</span> tf.variable_scope(<span class="st">&quot;dense_output&quot;</span>):
        <span class="cf">return</span> tf.layers.dense(
                prev_output, 
                output_dim, 
                activation<span class="op">=</span>output_activation)</code></pre></div>
<p>This code creates a weight matrix and bias vector for each hidden layer, one for the output layer, and allows the caller to specify the input, hidden, and output dimension, along with the activations for the hidden and output layers.</p>
<h3 id="generating-fake-data">Generating Fake Data</h3>
<p>Using the components we’ve implemented, we’re now going to build the generative portion of the model. In order to sample from the conditional distributions <span class="math inline">\(p_{G_x}(x|y)\)</span> and <span class="math inline">\(p_{G_y}(y|x)\)</span> we’ll need a function that takes two inputs 1) some noise and 2) a sample from the other domain. The noise can be thought of as a source of randomness and the sample as the value of the variable we are conditioning on. To model this function we’ll use a feedforward neural network which learns how to transform the sample from the noise distribution into samples from the conditional distribution.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> generator(<span class="bu">input</span>):
    <span class="cf">return</span> feedforward(<span class="bu">input</span>, <span class="dv">3</span>, num_units_gen, <span class="dv">1</span>, num_layers_gen, hidden_activation)

<span class="cf">with</span> tf.variable_scope(<span class="st">&quot;generator_xy&quot;</span>):
    x_given_y <span class="op">=</span> generator(z_y_samples)

<span class="cf">with</span> tf.variable_scope(<span class="st">&quot;generator_yx&quot;</span>):
    y_given_x <span class="op">=</span> generator(x_z_samples)

fake_x_pairs <span class="op">=</span> tf.concat((x_given_y, y_samples_e), <span class="dv">1</span>)
fake_y_pairs <span class="op">=</span> tf.concat((x_samples_e, y_given_x), <span class="dv">1</span>)</code></pre></div>
<p>Here we create a scope for each generator. The <span class="math inline">\(G_x\)</span> network in the <code>generator_xy</code> scope generates a sample from domain <span class="math inline">\(x\)</span> given a noise sample <span class="math inline">\(z\)</span> and a sample from domain <span class="math inline">\(y\)</span>, while the <span class="math inline">\(G_y\)</span> network in the <code>generator_yx</code> scope generates a sample from domain <span class="math inline">\(y\)</span> given a noise sample and a sample from domain <span class="math inline">\(x\)</span>.</p>
<h3 id="the-discriminators">The Discriminators</h3>
<p>Our discriminators are modeled by simple feedforward networks as well:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> discriminator(<span class="bu">input</span>):
    <span class="cf">return</span> feedforward(<span class="bu">input</span>, <span class="dv">2</span>, num_units_disc, <span class="dv">1</span>, num_layers_disc, hidden_activation, tf.nn.sigmoid)

<span class="cf">with</span> tf.variable_scope(<span class="st">&quot;disc_real_or_fake&quot;</span>) <span class="im">as</span> d_rf_scope:
    fake_x_scores_drf <span class="op">=</span> discriminator(fake_x_pairs)
    d_rf_scope.reuse_variables()
    real_scores_drf <span class="op">=</span> discriminator(joint_samples)
    fake_y_scores_drf <span class="op">=</span> discriminator(fake_y_pairs)

<span class="cf">with</span> tf.variable_scope(<span class="st">&quot;disc_fake_x_or_fake_y&quot;</span>) <span class="im">as</span> d_fxfy_scope:
    fake_x_scores_dfxfy <span class="op">=</span> discriminator(fake_x_pairs)
    d_fxfy_scope.reuse_variables()
    fake_y_scores_dfxfy <span class="op">=</span> discriminator(fake_y_pairs)</code></pre></div>
<p>We organize our code into two scopes, <code>disc_real_fake</code> for our real vs. fake discriminator and <code>disc_fake_x_or_fake_y</code> for our discriminator of fake sample types. This keeps our code nicely organized, and will also allow us to easily select which variables we want to train during adversarial learning. It’s important to notice that we only compute scores for <code>disc_fake_x_or_fake_y</code> on <em>fake</em> samples, and completely ignore <em>real</em> samples because it is meant to force the two generators to converge to the same distribution.</p>
<h3 id="minimizing-the-discriminator-loss">Minimizing the Discriminator Loss</h3>
<p>The objective of the discriminators is to 1) distinguish between real and fake samples and 2) distinguish between the two kinds of fake samples. Using this as a blueprint, <code>disc_real_fake</code>’s loss is designed to have the <span class="math inline">\(D_1\)</span> network learn to classify the real pairs as <code>1</code> and either of the fake pairs as <code>0</code>.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">loss_real_fake_disc <span class="op">=</span> tf.losses.log_loss(ZEROS, fake_x_scores_drf) <span class="op">\</span>
    <span class="op">+</span> tf.losses.log_loss(ONES, real_scores_drf) <span class="op">\</span>
    <span class="op">+</span> tf.losses.log_loss(ZEROS, fake_y_scores_drf)</code></pre></div>
<p>Similarly, the loss of <code>disc_fake_x_or_fake_y</code> is designed to coerce the <span class="math inline">\(D_2\)</span> network to classify pairs with a fake <span class="math inline">\(y\)</span> component as <code>1</code> and classify pairs with a fake <span class="math inline">\(x\)</span> component as <code>0</code>:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">loss_fake_x_fake_y_disc <span class="op">=</span> tf.losses.log_loss(ONES, fake_y_scores_dfxfy) <span class="op">\</span>
    <span class="op">+</span> tf.losses.log_loss(ZEROS, fake_x_scores_dfxfy)</code></pre></div>
<p>The total loss is simply the sum of the two discriminator losses. A training step consists of a gradient computation with respect to the discriminator variables, and then perturbing the network’s weights in a direction which allows the two discriminators to minimize the total loss. This operation is encapsulated in the <code>minimize</code> method of the built in <code>AdamOptimizer</code>. The learning rate of <code>0.0025</code> was chosen because the results were pretty good, and it also converged relatively quickly.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">loss_discriminators <span class="op">=</span> loss_real_fake_disc <span class="op">+</span> loss_fake_x_fake_y_disc

train_step_discriminators <span class="op">=</span> tf.train.AdamOptimizer(learning_rate<span class="op">=</span><span class="fl">0.0025</span>).minimize(loss_discriminators, var_list<span class="op">=</span>discriminator_vars)</code></pre></div>
<h3 id="minimizing-the-generator-loss">Minimizing the Generator Loss</h3>
<p>The goal of the generators is to generate samples that are indistinguishable from real samples. In essence, we design the generator losses so that minimizing the generator loss <em>maximizes</em> the discriminator loss. Since the discriminators only have binary labels, we have the generators learn to generate samples that result in discriminator scores closer to the label <em>opposite</em> to the label specified in the discriminator objective. In code:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">loss_gen_x_y <span class="op">=</span> tf.losses.log_loss(ONES, fake_x_scores_drf) <span class="op">\</span>
    <span class="op">+</span> tf.losses.log_loss(ONES, fake_x_scores_dfxfy)

loss_gen_y_x <span class="op">=</span> tf.losses.log_loss(ONES, fake_y_scores_drf) <span class="op">\</span>
    <span class="op">+</span> tf.losses.log_loss(ZEROS, fake_y_scores_dfxfy)

loss_generators <span class="op">=</span> loss_gen_x_y <span class="op">+</span> loss_gen_y_x

train_step_generators <span class="op">=</span> tf.train.AdamOptimizer(learning_rate<span class="op">=</span><span class="fl">0.0025</span>).minimize(loss_generators, var_list<span class="op">=</span>generator_vars)</code></pre></div>
<p>The losses here show how the generator objective is the inverse of the discriminator objective. We coerce <code>fake_x_scores_drf</code>, <code>fake_x_scores_dfxfy</code>, and <code>fake_y_scores_drf</code> to the label <code>1</code> and <code>fake_y_scores_dfxfy</code> to label <code>0</code>, the exact opposite of the labels in the discriminator loss. We once again use the <code>AdamOptimizer</code> to minimize the generator loss with respect to the generator variables.</p>
<h3 id="training-procedure">Training Procedure</h3>
<p>Now the final step is generate our samples and train both the discriminators and the generators simultaneously. The data distribution we are trying to approximate is a mixture of 4 bivariate gaussians with means and variances described in the <a href="https://papers.nips.cc/paper/7109-triangle-generative-adversarial-networks">paper</a> and our noise distribution is a guassian with mean 0 and variance 10. The higher variance is useful to make sure the noise distribution has mass over the support of the distribution we are trying to sample from. This is a small optimization that means the generator network no longer needs to learn to stretch the space of the noise distribution to match the sample space of the data distribution. This speeds up training time because the network has fewer properties that it needs to learn. We adopt a simplified training procedure to get faster results on a 2.6GHz laptop CPU. First we sample 1000 pairs from our data distribution. 500 act as supervised labeled pairs and 500 act as our independent <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> samples to provide to the generators to generate the fake <span class="math inline">\(x\)</span> and fake <span class="math inline">\(y\)</span> samples. We then pass the data to the respective training steps for the discriminator and generator. We iterate through this process 1000 times. <a href="https://github.com/mlazos/triangle-gan-tf">The full code is available on GitHub</a>.</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">1000</span>):
    joint_input <span class="op">=</span> generate_samples(<span class="dv">125</span>)

    np.random.shuffle(joint_input)

    temp_input <span class="op">=</span> generate_samples(<span class="dv">125</span>)
    
    np.random.shuffle(temp_input)
    x_input <span class="op">=</span> temp_input[:, <span class="dv">0</span>]
    np.random.shuffle(temp_input)
    y_input <span class="op">=</span> temp_input[:, <span class="dv">1</span>]
    z_input <span class="op">=</span> np.random.multivariate_normal([<span class="dv">0</span>,<span class="dv">0</span>], [[<span class="fl">10.0</span>, <span class="fl">10.0</span>], [<span class="fl">10.0</span>, <span class="fl">10.0</span>]], <span class="dv">4</span> <span class="op">*</span> <span class="dv">125</span>)

    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">9</span>):
        train_step_discriminators.run({x_samples:x_input, joint_samples:joint_input, y_samples:y_input, z_samples: z_input})
    
    train_step_generators.run({x_samples:x_input, joint_samples:joint_input, y_samples:y_input, z_samples: z_input})</code></pre></div>
<p>You may notice that we run the discriminator training step 10 times for each generator training step. This has been <a href="https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">shown</a> to have better convergence properties and avoids the scenario where the generators learn to fool the discriminator by “playing it safe” and generating less diverse samples, i.e. mapping many samples of the noise distribution to the same value of the conditional distribution. By training the discriminator more, we allow the discriminator to better generalize and accept more diverse samples. In our case though, this is more to allow the networks to converge faster. After training the networks, we should get something like the following.</p>
<table>
<thead>
<tr class="header">
<th align="center"><img src="../resources/triangle_gan_joint.png" style="width:100.0%" /></th>
<th align="center"><img src="../resources/triangle_gan_x_given_y.png" style="width:100.0%" /></th>
<th align="center"><img src="../resources/triangle_gan_y_given_x.png" style="width:100.0%" /></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(p(x,y)\)</span></td>
<td align="center"><span class="math inline">\(p_{G_x}(x,y)\)</span></td>
<td align="center"><span class="math inline">\(p_{G_y}(x,y)\)</span></td>
</tr>
</tbody>
</table>
<p><br></p>
<p>And with that we’re finished! Take a look at the extensions below, or check out the <a href="https://github.com/mlazos/triangle-gan-tf">full code</a>.</p>
<h3 id="closing-thoughts">Closing Thoughts</h3>
<p>I was pretty surprised at how sensitive this GAN is to its hyperparameters. Even small adjustments to the learning rate can dramatically alter the final distributions. Another surprise for me was how much more effective using tanh vs leaky relu was for these networks. I suspect this is due to the dying relu problem, because the learning rate is set pretty high in order to get faster convergence. This could be a good tensorflow debugging exercise.</p>
<h3 id="extensions">Extensions</h3>
<ul>
<li><p>Lower the number of true joint samples we provide to the model during training, this would certainly increase the time taken to converge, but it would show off the main advantage of the model - that it can learn the joint distribution with a few paired samples.</p></li>
<li><p>Train the model longer on more data. This should result in sharper approximated distributions.</p></li>
<li><p>Generate a 2D heat map of the decision boundary for the discriminator networks and verify that they have converged to the optimal values.</p></li>
</ul>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
                </div>
            </div>
        </div>
</body>
</html>
